{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:50:50.444964Z",
     "start_time": "2020-02-26T15:50:47.842863Z"
    }
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import requests\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb6c75e046e49eba90519b837e768a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('labels_new_v3.txt', 'r') as inf:\n",
    "    labels = defaultdict(list)\n",
    "    for line in tqdm(inf):\n",
    "        qid, label = line.strip('\\n').split(':', 1)\n",
    "        labels[qid].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:50:51.529471Z",
     "start_time": "2020-02-26T15:50:51.518489Z"
    }
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, job_name=None):\n",
    "        self.job_name = job_name\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start_time = time()\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        end_time = time()\n",
    "        passed_time = end_time - self.start_time\n",
    "        line = f'{self.job_name} executed in {passed_time:.3f} s.' if self.job_name else f'{passed_time:.3f} s.'\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:50:52.807526Z",
     "start_time": "2020-02-26T15:50:52.800579Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_read(filename):\n",
    "    with open(filename, 'r') as inf:\n",
    "        res = json.load(inf)\n",
    "    return res\n",
    "\n",
    "def json_dump(obj, filename, ea=False, indent=4):\n",
    "    with open(filename, 'w') as ouf:\n",
    "        json.dump(obj, ouf, ensure_ascii=ea, indent=indent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply analyzer to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:50:56.507772Z",
     "start_time": "2020-02-26T15:50:56.497606Z"
    }
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "simple_tokenizer = CountVectorizer(lowercase=False, token_pattern='\\w+').build_analyzer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return(' '.join(simple_tokenizer(text)))\n",
    "\n",
    "def analyzer(text):\n",
    "    return(' '.join(simple_analyzer(''.join(mystem.lemmatize(text)))))\n",
    "\n",
    "def analyzer2(text):\n",
    "    return(''.join(mystem.lemmatize(' '.join(simple_analyzer(text)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996b5b05ce9b4acbbee17588d1ded978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# with open('labels_new_v3_test.txt', 'r') as inf, open('labels_mystem_test.txt', 'w') as ouf:\n",
    "#     for line in tqdm(inf):\n",
    "#         qid, label = line.strip('\\n').split(':', 1)\n",
    "#         ouf.write(qid + ':' + analyzer(label) + '\\n')\n",
    " \n",
    "# create file with only tokenized labels\n",
    "with open('labels_raw.txt', 'r') as inf, open('labels_token.txt', 'w') as ouf:\n",
    "    for line in tqdm(inf):\n",
    "        qid, label = line.strip('\\n').split(':', 1)\n",
    "        ouf.write(qid + ':' + tokenizer(label) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create elastic search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:02.838927Z",
     "start_time": "2020-02-26T15:51:02.834349Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360, 'maxsize': 25}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def create_es_action(key, data, index):\n",
    "    es_document = {'qid': key, 'label': data}\n",
    "    es_action = {\n",
    "        \"_index\": index,\n",
    "        \"_source\": es_document\n",
    "    }\n",
    "    return es_action\n",
    "\n",
    "documents_file = 'labels_token.txt'\n",
    "\n",
    "def label_list_documents_generator():\n",
    "    with open(documents_file, 'r') as file:\n",
    "        prev_qid = None\n",
    "        cur_label_list = []\n",
    "        for line in tqdm(file):\n",
    "            qid, label = line.split(':', 1)\n",
    "            if qid == prev_qid:\n",
    "                cur_label_list.append(label.strip('\\n'))\n",
    "            else:\n",
    "                if len(cur_label_list) > 0:\n",
    "                    yield create_es_action(prev_qid, cur_label_list, 'label_list')\n",
    "\n",
    "                prev_qid = qid\n",
    "                cur_label_list = [label.strip('\\n')]\n",
    "        \n",
    "        if len(cur_label_list) > 0:\n",
    "            yield create_es_action(prev_qid, cur_label_list, 'label_list')\n",
    "            \n",
    "def label_single_documents_generator():\n",
    "    with open(documents_file, 'r') as file:\n",
    "        for line in tqdm(file):\n",
    "            qid, label = line.split(':', 1)\n",
    "            yield create_es_action(qid, label.strip('\\n'), 'label_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'label_single'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"label\": {\n",
    "                \"type\": \"text\",\n",
    "                'analyzer': 'snowball_stemmer'\n",
    "#                 \"fields\": {\n",
    "#                     \"shingle\": {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"analyzer\": \"shingle_analyzer\"\n",
    "#                     }\n",
    "#                 }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"analysis\" : {\n",
    "            \"analyzer\" : {\n",
    "                \"snowball_stemmer\" : {\n",
    "                    \"tokenizer\" : \"whitespace\",\n",
    "                    \"filter\" : ['lowercase', \"snow_stem\"]\n",
    "                }\n",
    "            },\n",
    "            \"filter\" : {\n",
    "                \"snow_stem\" : {\n",
    "                    \"type\" : \"snowball\",\n",
    "                    \"language\" : \"Russian\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "#         \"analysis\": {\n",
    "#             \"analyzer\": {\n",
    "#                 \"shingle_analyzer\": {\n",
    "#                     \"tokenizer\": \"standard\",\n",
    "#                     \"filter\": [\n",
    "#                         \"custom_shingle\"\n",
    "#                     ]\n",
    "#                 }\n",
    "#             },\n",
    "#             \"filter\": {\n",
    "#                 \"custom_shingle\": {\n",
    "#                     \"type\": \"shingle\",\n",
    "#                     \"min_shingle_size\": \"2\",\n",
    "#                     \"max_shingle_size\": \"3\"\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(index='label_list')\n",
    "es.indices.create(index='label_list', body=settings)\n",
    "\n",
    "es.indices.delete(index='label_single')\n",
    "es.indices.create(index='label_single', body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccc1f6d1a3445efa4d601983be8d65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ok, result in parallel_bulk(es, label_single_documents_generator(), queue_size=8, thread_count=8, chunk_size=1000):\n",
    "    if not ok:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic query builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T10:07:43.020654Z",
     "start_time": "2020-01-21T10:07:43.014130Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('russian_stopwords.txt', 'r') as inf:\n",
    "    stopwords = []\n",
    "    for line in inf:\n",
    "        stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:20.340200Z",
     "start_time": "2020-02-26T15:51:20.333997Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_pos_tags = [\n",
    "    'ADVPRO',\n",
    "    'APRO',\n",
    "    'CONJ',\n",
    "    'INTJ',\n",
    "    'PART',\n",
    "    'PR',\n",
    "    'SPRO',\n",
    "    'V',\n",
    "    'ADV'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:20.942682Z",
     "start_time": "2020-02-26T15:51:20.935249Z"
    }
   },
   "outputs": [],
   "source": [
    "# class TokenFilter:\n",
    "#     def __init__(self, stopwords, stop_pos_tags):\n",
    "#         self.stopwords = set(stopwords)\n",
    "#         self.stop_pos_tags = set(stop_pos_tags)\n",
    "        \n",
    "#     def is_good(self, token):\n",
    "#         if self.has_first_capital(token):\n",
    "#             return True\n",
    "#         if self.pass_stopwords(token) and \\\n",
    "#            self.pass_length(token):\n",
    "#             return True\n",
    "#         return False\n",
    "        \n",
    "#     def pass_stopwords(self, token):\n",
    "#         if token in self.stopwords:\n",
    "#             return False\n",
    "#         return True\n",
    "    \n",
    "#     def pass_length(self, token):\n",
    "#         if len(token) < 2:\n",
    "#             return False\n",
    "#         return True\n",
    "    \n",
    "#     def has_first_capital(self, token):\n",
    "#         if token[0].isupper():\n",
    "#             return True\n",
    "#         return False\n",
    "\n",
    "class Morpher:\n",
    "    def __init__(self):\n",
    "        self.stop_pos_tags = set([\n",
    "            'ADVPRO',\n",
    "            'APRO',\n",
    "            'CONJ',\n",
    "            'INTJ',\n",
    "            'PART',\n",
    "            'PR',\n",
    "            'SPRO',\n",
    "            'V',\n",
    "            'ADV'\n",
    "        ])\n",
    "        self.mystem = Mystem()\n",
    "        \n",
    "    def analyze(self, text):\n",
    "        return self.mystem.analyze(text)\n",
    "    \n",
    "    def approve_tag(self, tag):\n",
    "        if tag in self.stop_pos_tags:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:22.085728Z",
     "start_time": "2020-02-26T15:51:22.055823Z"
    }
   },
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, text, tokenizer, morpher):\n",
    "        self.text = text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.morpher = morpher\n",
    "        self.get_tokens()\n",
    "        self.get_filtered_tokens()\n",
    "        self.get_token_ngrams()\n",
    "        self.get_capital_pairs()\n",
    "        \n",
    "    def get_tokens(self):\n",
    "        self.tokens = self.tokenizer(self.text).split()\n",
    "        return self.tokens\n",
    "    \n",
    "    def get_filtered_tokens(self):\n",
    "        self.filtered_tokens = []\n",
    "        analysis = self.morpher.analyze(' '.join(self.tokens))\n",
    "        for i, ta in enumerate(analysis):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if 'analysis' in ta:\n",
    "                if ta['text'][0].isupper() and len(ta['text']) > 1:\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "                    continue\n",
    "                if not ta['analysis']:\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "                    continue\n",
    "                pos_tag = ta['analysis'][0]['gr'].split(',', 1)[0].split('=', 1)[0]\n",
    "                if self.morpher.approve_tag(pos_tag):\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "        return self.filtered_tokens\n",
    "    \n",
    "    def get_token_ngrams(self, n=3):\n",
    "        self.token_ngrams = []\n",
    "        for i in range(len(self.tokens) - (n - 1)):\n",
    "            self.token_ngrams.append(' '.join(self.tokens[i:(i + n)]))\n",
    "        return self.token_ngrams\n",
    "    \n",
    "    def get_capital_pairs(self):\n",
    "        self.capital_pairs = []\n",
    "        for i in range(1, len(self.tokens) - 1):\n",
    "            if self.tokens[i][0].isupper() and \\\n",
    "               len(self.tokens[i]) > 1 and \\\n",
    "               self.tokens[i + 1][0].isupper() and \\\n",
    "               len(self.tokens[i + 1]) > 1:\n",
    "                self.capital_pairs.append(' '.join(self.tokens[i:(i + 2)]))\n",
    "        return self.capital_pairs\n",
    "    \n",
    "    def build_match_query(self, query, fuzziness='AUTO'):\n",
    "        return  { \n",
    "                    'match': {\n",
    "                        'label': {\n",
    "                            'query': query,\n",
    "                            \"fuzziness\": fuzziness,\n",
    "                            \"prefix_length\": 1,\n",
    "                            'fuzzy_transpositions': False\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "    \n",
    "    def build_phrase_query(self, query):\n",
    "        return  { \n",
    "                    'match_phrase': {\n",
    "                        'label': query\n",
    "                    }\n",
    "                }\n",
    "    \n",
    "    def get_phrase_queries(self):\n",
    "        qs = []\n",
    "        for ng in self.token_ngrams:\n",
    "            qs.append(self.build_phrase_query(ng))\n",
    "        for cp in self.capital_pairs:\n",
    "            qs.append(self.build_phrase_query(cp))\n",
    "        return qs\n",
    "    \n",
    "    def get_fulltext_queries(self):\n",
    "        return [self.build_match_query(' '.join(self.filtered_tokens))]\n",
    "    \n",
    "    def get_single_capital_queries(self):\n",
    "        qs = []\n",
    "        for token in self.filtered_tokens:\n",
    "            if token[0].isupper() and len(token) > 2:\n",
    "                qs.append(self.build_phrase_query(token))\n",
    "        return qs\n",
    "    \n",
    "    def get_partial_queries(self):\n",
    "        qs = []\n",
    "        n = len(self.filtered_tokens)\n",
    "        for i in range(0, n, 2):\n",
    "            subtext = ' '.join(self.filtered_tokens[i:(min(i + 3, n))])\n",
    "            qs.append(self.build_match_query(subtext, fuzziness=0))\n",
    "        return qs\n",
    "        \n",
    "    def build_es_query(self, queries):\n",
    "        return  {\n",
    "                    'query': {\n",
    "                        'bool': {\n",
    "                            'should': queries\n",
    "                        }\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:23.308099Z",
     "start_time": "2020-02-26T15:51:23.296756Z"
    }
   },
   "outputs": [],
   "source": [
    "class QueryTarget(Query):\n",
    "    def get_filtered_tokens(self):\n",
    "        self.filtered_tokens = []\n",
    "        analysis = self.morpher.analyze(' '.join(self.tokens))\n",
    "        for ta in analysis:\n",
    "            if 'analysis' in ta:\n",
    "                if ta['text'][0].isupper() and len(ta['text']) > 1:\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "                    continue\n",
    "                if not ta['analysis']:\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "                    continue\n",
    "                pos_tag = ta['analysis'][0]['gr'].split(',', 1)[0].split('=', 1)[0]\n",
    "                if self.morpher.approve_tag(pos_tag):\n",
    "                    self.filtered_tokens.append(ta['text'])\n",
    "        return self.filtered_tokens\n",
    "    \n",
    "    def get_token_ngrams(self, n=2):\n",
    "        self.token_ngrams = [' '.join(self.tokens)]\n",
    "        for i in range(len(self.tokens) - (n - 1)):\n",
    "            self.token_ngrams.append(' '.join(self.tokens[i:(i + n)]))\n",
    "        return self.token_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:37.316569Z",
     "start_time": "2020-02-26T15:51:35.886134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.421 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrph = Morpher()\n",
    "with Timer():\n",
    "    q = Query('Луна', tokenizer=tokenizer, morpher=mrph)\n",
    "q.get_phrase_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:51.904505Z",
     "start_time": "2020-02-26T15:51:51.896154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'bool': {'should': []}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.build_es_query(q.get_phrase_queries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T16:36:28.870916Z",
     "start_time": "2020-03-16T16:36:24.417395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['жители', 'Таллина', 'Толстую', 'Маргариту']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': {'value': 1, 'relation': 'eq'},\n",
       " 'max_score': 18.215916,\n",
       " 'hits': [{'_index': 'label_single',\n",
       "   '_type': '_doc',\n",
       "   '_id': 'Jt_vpmwBg_1FN09HLgUG',\n",
       "   '_score': 18.215916,\n",
       "   '_source': {'qid': 'Q282994', 'label': 'Толстая Маргарита'}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = tokenizer('Кого сыграл Жан Рено в фильме \"Ее звали Никита\"?')\n",
    "# doc = {\n",
    "#     'query': {\n",
    "#         \"fuzzy\" : {\n",
    "#             \"labels\" : {\n",
    "#                 \"value\": \"домашняя кошка\",\n",
    "#                 \"fuzziness\": 2,\n",
    "#                 \"prefix_length\": 0,\n",
    "#                 \"max_expansions\": 100,\n",
    "#                 'transpositions': False\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# doc = {\n",
    "#     'query': {\n",
    "#         'match': {\n",
    "#             'label': {\n",
    "#                 'query': query,\n",
    "#                 \"fuzziness\": 'AUTO',\n",
    "#                 \"prefix_length\": 1,\n",
    "#                 'fuzzy_transpositions': False\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# doc = {\n",
    "#     'query': {\n",
    "#         'match_phrase': {\n",
    "#             'label': query\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "doc = {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [\n",
    "#                 {\n",
    "#                     'match_phrase': {\n",
    "#                         'label': 'Жан Рено'\n",
    "#                     }\n",
    "#                 },\n",
    "#                 {\n",
    "#                     'match_phrase': {\n",
    "#                         'label': 'Ее звали Никита'\n",
    "#                     }\n",
    "#                 },\n",
    "                { \n",
    "                    'match': {\n",
    "                        'label':\n",
    "                        {\n",
    "                            'query': 'домашняя'\n",
    "#                             \"fuzziness\": 'AUTO',\n",
    "#                             \"prefix_length\": 1,\n",
    "#                             'fuzzy_transpositions': False\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                                { \n",
    "                    'match': {\n",
    "                        'label':\n",
    "                        {\n",
    "                            'query': 'кошка'\n",
    "#                             \"fuzziness\": 'AUTO',\n",
    "#                             \"prefix_length\": 1,\n",
    "#                             'fuzzy_transpositions': False\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# doc = {\n",
    "#     'query': {\n",
    "#         'match_all': {}\n",
    "#     }\n",
    "# }\n",
    "q = Query('Что покажут жители Таллина, если вы захотите взглянуть на Толстую Маргариту?', tokenizer=tokenizer, morpher=mrph)\n",
    "print(q.filtered_tokens)\n",
    "doc = q.build_es_query(q.get_phrase_queries())\n",
    "\n",
    "res = es.search(index='label_single', body=doc, size=20)\n",
    "res['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:51:57.728903Z",
     "start_time": "2020-02-26T15:51:57.691608Z"
    }
   },
   "outputs": [],
   "source": [
    "class Matcher:\n",
    "    def __init__(self, es_instance):\n",
    "        self.es = es_instance\n",
    "        \n",
    "    def _smooth_score(self, score, d=5):\n",
    "        score = int(score)\n",
    "        while score % d != 0:\n",
    "            score += 1\n",
    "        return score\n",
    "    \n",
    "    def _parse_id(self, qid):\n",
    "        return int(qid[1:])\n",
    "    \n",
    "    def _sorting_key(self, match):\n",
    "        score = self._smooth_score(match['score'])\n",
    "        qid = self._parse_id(match['qid'])\n",
    "        return score, -qid\n",
    "    \n",
    "    def get_names_and_descriptions(self, qids):\n",
    "        if not qids:\n",
    "            return {}\n",
    "        qids_list = '|'.join(qids)\n",
    "        wikiapi_query = f'https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&ids={qids_list}&languages=ru&props=labels|descriptions'\n",
    "        resp = requests.get(wikiapi_query).json()\n",
    "        result = {}\n",
    "        for qid in qids:\n",
    "            cur_data = resp['entities'][qid]\n",
    "            name = None\n",
    "            if 'labels' in cur_data:\n",
    "                if 'ru' in cur_data['labels']:\n",
    "                    name = cur_data['labels']['ru']['value']\n",
    "            description = None\n",
    "            if 'descriptions' in cur_data:\n",
    "                if 'ru' in cur_data['descriptions']:\n",
    "                    description = cur_data['descriptions']['ru']['value']\n",
    "            result[qid] = {'name': name, 'description': description}\n",
    "        return result\n",
    "    \n",
    "    def get_wikipedia_pageviews(self, titles_dict):\n",
    "        if not titles_dict:\n",
    "            return\n",
    "        titles_list = list(map(lambda s: s.replace(' ', '_'), titles_dict.keys()))\n",
    "        for i in range(len(titles_list)):\n",
    "            titles = '|'.join(titles_list)\n",
    "            wikiapi_query = f'https://ru.wikipedia.org/w/api.php?action=query&format=json&prop=pageviews&pvipdays=30&titles={titles}'\n",
    "            resp = requests.get(wikiapi_query).json()\n",
    "            if 'batchcomplete' in resp:\n",
    "                break\n",
    "#         print(titles_list)\n",
    "#         print(resp)\n",
    "        pages_data = (resp['query']['pages'])\n",
    "#         print(len(titles_list))\n",
    "#         print(len(pages_data.values()))\n",
    "        \n",
    "        for entry in pages_data.values():\n",
    "            view_stats = entry['pageviews']\n",
    "            views = sum(filter(None, view_stats.values()))\n",
    "            cur_title = entry['title']\n",
    "            titles_dict[cur_title] = views\n",
    "    \n",
    "    def get_wikipedia_pages(self, qids):\n",
    "        if not qids:\n",
    "            return {}\n",
    "        qids_list = '|'.join(qids)\n",
    "        wikiapi_query = f'https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&ids={qids_list}&sitefilter=ruwiki&props=sitelinks'\n",
    "        resp = requests.get(wikiapi_query).json()\n",
    "        result = {}\n",
    "        views = {}\n",
    "        for qid in qids:\n",
    "            cur_data = resp['entities'][qid]\n",
    "            wiki_title = None\n",
    "            if 'sitelinks' in cur_data and 'ruwiki' in cur_data['sitelinks'] and 'title' in cur_data['sitelinks']['ruwiki']:\n",
    "                wiki_title = cur_data['sitelinks']['ruwiki']['title']\n",
    "                views[wiki_title] = 0\n",
    "            result[qid] = {'ruwiki': wiki_title}\n",
    "            \n",
    "        self.get_wikipedia_pageviews(views)\n",
    "        for qid in qids:\n",
    "            cur_title = result[qid]['ruwiki']\n",
    "            if cur_title is not None:\n",
    "                result[qid]['views'] = views[cur_title]\n",
    "            else:\n",
    "                result[qid]['views'] = 0\n",
    "        return result\n",
    "    \n",
    "#     def get_wikipedia_pageviews(self, wiki_title):\n",
    "#         wiki_title = wiki_title.replace(' ', '_')\n",
    "#         wikiapi_query = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/ru.wikipedia/all-access/all-agents/{wiki_title}/monthly/2019010100/2019013100'\n",
    "#         resp = requests.get(wikiapi_query).json()\n",
    "#         return resp['items'][0]['views']\n",
    "\n",
    "    def _apply_ranking(self, matches, relative_rate=0.9):\n",
    "        if len(matches) == 0:\n",
    "            return matches\n",
    "        \n",
    "        matches = sorted(matches, key=lambda m: m['score'], reverse=True)      \n",
    "        \n",
    "        cur_max_pos = 0\n",
    "        cur_pos = 1\n",
    "        while cur_pos < len(matches):\n",
    "            cur_max_score = matches[cur_max_pos]['score']\n",
    "            while cur_pos < len(matches) and matches[cur_pos]['score'] >= relative_rate * matches[cur_pos - 1]['score']:\n",
    "                cur_pos += 1\n",
    "            matches[cur_max_pos:cur_pos] = sorted(matches[cur_max_pos:cur_pos], key=lambda m: m['views'], reverse=True)\n",
    "            cur_max_pos = cur_pos\n",
    "            cur_pos = cur_max_pos + 1\n",
    "            \n",
    "        return matches\n",
    "        \n",
    "    def get_query_matches(self, query, n_matches=30):\n",
    "        es_result = es.search(index='label_single', body=query, size=n_matches)['hits']\n",
    "        matches_dict = {}\n",
    "        for entry in es_result['hits']:\n",
    "            qid = entry['_source']['qid']\n",
    "            if qid not in matches_dict:\n",
    "                matches_dict[qid] = entry['_source']\n",
    "                matches_dict[qid]['score'] = entry['_score']\n",
    "        \n",
    "        names_and_descriptions = self.get_names_and_descriptions(matches_dict.keys())\n",
    "        for qid, nds in names_and_descriptions.items():\n",
    "            matches_dict[qid].update(nds)\n",
    "            \n",
    "        wikipedia_pages = self.get_wikipedia_pages(matches_dict.keys())\n",
    "        for qid, wps in wikipedia_pages.items():\n",
    "            matches_dict[qid].update(wps)\n",
    "            \n",
    "#         for qid in tqdm(matches_dict):\n",
    "#             match = matches_dict[qid]\n",
    "#             match['views'] = 0\n",
    "#             if match['ruwiki'] is not None:\n",
    "#                 match['views'] = self.get_wikipedia_pageviews(match['ruwiki'])\n",
    "            \n",
    "#         matches = sorted(matches_dict.values(), key=self._sorting_key, reverse=True)\n",
    "        matches = self._apply_ranking(list(matches_dict.values()))\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T16:36:38.395620Z",
     "start_time": "2020-03-16T16:36:38.367624Z"
    }
   },
   "outputs": [],
   "source": [
    "mtc = Matcher(es_instance=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T16:37:08.727908Z",
     "start_time": "2020-03-16T16:37:08.714718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'bool': {'should': [{'match_phrase': {'label': 'Что покажут жители'}},\n",
       "    {'match_phrase': {'label': 'покажут жители Таллина'}},\n",
       "    {'match_phrase': {'label': 'жители Таллина если'}},\n",
       "    {'match_phrase': {'label': 'Таллина если вы'}},\n",
       "    {'match_phrase': {'label': 'если вы захотите'}},\n",
       "    {'match_phrase': {'label': 'вы захотите взглянуть'}},\n",
       "    {'match_phrase': {'label': 'захотите взглянуть на'}},\n",
       "    {'match_phrase': {'label': 'взглянуть на Толстую'}},\n",
       "    {'match_phrase': {'label': 'на Толстую Маргариту'}},\n",
       "    {'match_phrase': {'label': 'Толстую Маргариту'}}]}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.build_es_query(q.get_single_capital_queries()[0])\n",
    "q.build_es_query(q.get_phrase_queries())\n",
    "# q.build_es_query(q.get_fulltext_queries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:15:30.094316Z",
     "start_time": "2020-01-28T12:15:27.795712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qid': 'Q2813',\n",
       "  'label': 'Кока кола',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Кока-кола',\n",
       "  'description': 'безалкогольный газированный напиток',\n",
       "  'ruwiki': 'Кока-кола',\n",
       "  'views': 32018},\n",
       " {'qid': 'Q3295867',\n",
       "  'label': 'Кока кола',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Кока-кола',\n",
       "  'description': None,\n",
       "  'ruwiki': 'The Coca-Cola Company',\n",
       "  'views': 11994},\n",
       " {'qid': 'Q4135566',\n",
       "  'label': 'Кафа город',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Генуэзская крепость (Феодосия)',\n",
       "  'description': 'Каффа',\n",
       "  'ruwiki': 'Генуэзская крепость (Феодосия)',\n",
       "  'views': 1610},\n",
       " {'qid': 'Q196378',\n",
       "  'label': 'Со кол город',\n",
       "  'score': 11.375547,\n",
       "  'name': 'Сокол',\n",
       "  'description': 'город в Сокольском районе Вологодской области России',\n",
       "  'ruwiki': 'Сокол (город)',\n",
       "  'views': 1510},\n",
       " {'qid': 'Q1104936',\n",
       "  'label': 'Коба город',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Коба (город)',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Коба (майя)',\n",
       "  'views': 737},\n",
       " {'qid': 'Q24672271',\n",
       "  'label': 'Город котов',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Город кошек',\n",
       "  'description': 'Полнометражный документальный фильм о бродячих кошках, населяющих город Стамбул',\n",
       "  'ruwiki': 'Город кошек',\n",
       "  'views': 320},\n",
       " {'qid': 'Q827432',\n",
       "  'label': 'Кота Кока',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Вилькабамба',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Вилькабамба',\n",
       "  'views': 309},\n",
       " {'qid': 'Q785223',\n",
       "  'label': 'Музей мумий',\n",
       "  'score': 12.290472,\n",
       "  'name': 'Музей мумий',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей мумий (Гуанахуато)',\n",
       "  'views': 281},\n",
       " {'qid': 'Q478455',\n",
       "  'label': 'Австрийский музей прикладного искусства',\n",
       "  'score': 12.148895,\n",
       "  'name': 'Австрийский музей прикладного искусства',\n",
       "  'description': 'музей в Вене',\n",
       "  'ruwiki': 'Музей прикладного искусства (Вена)',\n",
       "  'views': 249},\n",
       " {'qid': 'Q5101500',\n",
       "  'label': 'Исторический музей города Кракова',\n",
       "  'score': 11.049572,\n",
       "  'name': 'Краковский исторический музей',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей Кракова',\n",
       "  'views': 235},\n",
       " {'qid': 'Q1134454',\n",
       "  'label': 'Коро город',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Коро',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Коро',\n",
       "  'views': 209},\n",
       " {'qid': 'Q330531',\n",
       "  'label': 'Кота город',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Кота',\n",
       "  'description': 'город в Раджастане, Индия',\n",
       "  'ruwiki': 'Кота (Раджастхан)',\n",
       "  'views': 144},\n",
       " {'qid': 'Q769416',\n",
       "  'label': 'Австралийский музей',\n",
       "  'score': 14.825106,\n",
       "  'name': 'Австралийский музей',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Австралийский музей',\n",
       "  'views': 119},\n",
       " {'qid': 'Q4306365',\n",
       "  'label': 'Музей кофе Санкт Петербург',\n",
       "  'score': 11.281676,\n",
       "  'name': 'Музей кофе (Санкт-Петербург)',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей кофе (Санкт-Петербург)',\n",
       "  'views': 97},\n",
       " {'qid': 'Q387292',\n",
       "  'label': 'Музей города Мосул',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Мосул',\n",
       "  'description': 'исторический музей в Ираке',\n",
       "  'ruwiki': 'Музей города Мосул',\n",
       "  'views': 59},\n",
       " {'qid': 'Q4956083',\n",
       "  'label': 'Музей чая и кофе',\n",
       "  'score': 11.281676,\n",
       "  'name': 'Музей чая и кофе',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей чая и кофе (Лондон)',\n",
       "  'views': 59},\n",
       " {'qid': 'Q1512466',\n",
       "  'label': 'Музей города Братиславы',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Братиславы',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей города Братиславы',\n",
       "  'views': 57},\n",
       " {'qid': 'Q4306316',\n",
       "  'label': 'Обнинский музей истории города',\n",
       "  'score': 11.049572,\n",
       "  'name': 'Музей истории города Обнинска',\n",
       "  'description': 'музей в городе Обнинске (Калужская область)',\n",
       "  'ruwiki': 'Музей истории города Обнинска',\n",
       "  'views': 56},\n",
       " {'qid': 'Q2578922',\n",
       "  'label': 'Музей города Осло',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Осло',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей города Осло',\n",
       "  'views': 53},\n",
       " {'qid': 'Q306628',\n",
       "  'label': 'Музей кофе Вена',\n",
       "  'score': 13.144338,\n",
       "  'name': 'Музей кофе (Вена)',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей кофе (Вена)',\n",
       "  'views': 49},\n",
       " {'qid': 'Q1954491',\n",
       "  'label': 'Музей города Кенигсберг',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Кёнигсберг',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей города Кёнигсберг',\n",
       "  'views': 41},\n",
       " {'qid': 'Q12130609',\n",
       "  'label': 'Музей истории города Краматорска',\n",
       "  'score': 11.049572,\n",
       "  'name': 'Музей истории города Краматорска',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей истории города Краматорска',\n",
       "  'views': 40},\n",
       " {'qid': 'Q21663286',\n",
       "  'label': 'Австрийский почтово телеграфный музей',\n",
       "  'score': 12.148895,\n",
       "  'name': 'Австрийский почтово-телеграфный музей',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Австрийский почтово-телеграфный музей',\n",
       "  'views': 30},\n",
       " {'qid': 'Q11786998',\n",
       "  'label': 'Музей истории города Люблина',\n",
       "  'score': 11.049572,\n",
       "  'name': 'Музей истории города Люблина',\n",
       "  'description': 'исторический музей',\n",
       "  'ruwiki': 'Музей истории города Люблина',\n",
       "  'views': 28},\n",
       " {'qid': 'Q932057',\n",
       "  'label': 'Кос Коб',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Кос Коб',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Кос-Коб (Коннектикут)',\n",
       "  'views': 23},\n",
       " {'qid': 'Q2403321',\n",
       "  'label': 'Музей города Белграда',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Белграда',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей города Белграда',\n",
       "  'views': 22},\n",
       " {'qid': 'Q20627357',\n",
       "  'label': 'Кош Кол',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Кош-Кол',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Кош-Кёль',\n",
       "  'views': 22},\n",
       " {'qid': 'Q2618426',\n",
       "  'label': 'Музей города Загреба',\n",
       "  'score': 12.873911,\n",
       "  'name': 'Музей города Загреба',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Музей города Загреба',\n",
       "  'views': 18},\n",
       " {'qid': 'Q1345954',\n",
       "  'label': 'Кота город',\n",
       "  'score': 13.625122,\n",
       "  'name': 'Кота',\n",
       "  'description': 'город в Японии',\n",
       "  'ruwiki': 'Кота (Япония)',\n",
       "  'views': 14},\n",
       " {'qid': 'Q4234724',\n",
       "  'label': 'Кос Комысь',\n",
       "  'score': 11.159221,\n",
       "  'name': 'Кос-Комысь',\n",
       "  'description': None,\n",
       "  'ruwiki': 'Кос-Комысь',\n",
       "  'views': 3}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtc.get_query_matches(q.build_es_query(q.get_fulltext_queries()))\n",
    "# mtc.get_query_matches(q.build_es_query(q.get_single_capital_queries()[0]))\n",
    "# mtc.get_query_matches(q.build_es_query(q.get_phrase_queries()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:52:10.666123Z",
     "start_time": "2020-02-26T15:52:10.639273Z"
    }
   },
   "outputs": [],
   "source": [
    "class Suggester:\n",
    "    def __init__(self, matcher, tokenizer, morpher):\n",
    "        self.matcher = matcher\n",
    "        self.tokenizer = tokenizer\n",
    "        self.morpher = morpher\n",
    "        \n",
    "    def _build_query(self, text):\n",
    "        return Query(text=text, tokenizer=self.tokenizer, morpher=self.morpher)\n",
    "    \n",
    "    def _get_matches(self, q, query_type):\n",
    "        if query_type == 'fulltext':\n",
    "            return self.matcher.get_query_matches(q.build_es_query(q.get_fulltext_queries()), n_matches=20)\n",
    "        if query_type == 'phrase':\n",
    "            return self.matcher.get_query_matches(q.build_es_query(q.get_phrase_queries()), n_matches=8)\n",
    "        if query_type == 'single':\n",
    "            single_queries = q.get_single_capital_queries()\n",
    "            return [self.matcher.get_query_matches(q.build_es_query(single_query), n_matches=10)\n",
    "                   for single_query in single_queries]\n",
    "        \n",
    "    def _select_matches(self, q, min_total=8, f=5, p=4, s=1):\n",
    "        matches = []\n",
    "        matches_qids = set()\n",
    "        \n",
    "#         print('# Phrase')\n",
    "        phrase_matches = self._get_matches(q, query_type='phrase')\n",
    "        if len(phrase_matches) > p:\n",
    "            phrase_matches = phrase_matches[:p]\n",
    "        for match in phrase_matches:\n",
    "            matches_qids.add(match['qid'])\n",
    "            match['source'] = 'phrase'\n",
    "#             print(match)\n",
    "        \n",
    "#         print('# Singles')\n",
    "        single_matches = self._get_matches(q, query_type='single')\n",
    "        single_matches_result = []\n",
    "        for single_match in single_matches:\n",
    "            if not single_match:\n",
    "                continue\n",
    "            top_match = single_match[0]\n",
    "            if top_match['qid'] not in matches_qids:\n",
    "                matches_qids.add(top_match['qid'])\n",
    "                top_match['source'] = 'single'\n",
    "                single_matches_result.append(top_match)\n",
    "#                 print(top_match)\n",
    "        single_matches_result = sorted(single_matches_result, key=lambda m: m['views'], reverse=True)\n",
    "        \n",
    "#         print('# Fulltext')\n",
    "        fulltext_matches = self._get_matches(q, query_type='fulltext')\n",
    "        fulltext_matches_result = []\n",
    "        f_cnt = 0\n",
    "        for match in fulltext_matches:\n",
    "            if match['qid'] not in matches_qids:\n",
    "                f_cnt += 1\n",
    "                matches_qids.add(match['qid'])\n",
    "                match['source'] = 'fulltext'\n",
    "                fulltext_matches_result.append(match)\n",
    "#                 print(match)\n",
    "            if len(matches_qids) >= min_total and f_cnt >= f:\n",
    "                break\n",
    "        fulltext_matches_result = sorted(fulltext_matches_result, key=lambda m: m['score'], reverse=True)\n",
    "                \n",
    "        matches.extend(phrase_matches)\n",
    "        matches.extend(fulltext_matches_result)\n",
    "        matches.extend(single_matches_result)\n",
    "        return matches\n",
    "    \n",
    "    def get_suggestions(self, text, answer=''):\n",
    "#         with Timer('Build query'):\n",
    "        q = self._build_query(text)\n",
    "        \n",
    "#         with Timer('Select matches'):\n",
    "        matches = self._select_matches(q)\n",
    "        return {\n",
    "            'text': text,\n",
    "            'answer': answer,\n",
    "            'matches': matches\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def pretty_print(entry):\n",
    "        lines = []\n",
    "        \n",
    "        matches = entry['matches']\n",
    "        query = entry['text']\n",
    "        \n",
    "        lines.append(f'Query: {query}\\n')\n",
    "        \n",
    "        for match in matches:\n",
    "            if match['name']:\n",
    "                lines.append(match['name'])\n",
    "            else:\n",
    "                lines.append('*no name*')\n",
    "\n",
    "            if match['description']:\n",
    "                desc = match['description']\n",
    "                lines.append(f'({desc})')\n",
    "\n",
    "            qid = match['qid']\n",
    "            lines.append(f'Link: https://www.wikidata.org/wiki/{qid}\\n')\n",
    "        \n",
    "        return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:52:11.050206Z",
     "start_time": "2020-02-26T15:52:11.039459Z"
    }
   },
   "outputs": [],
   "source": [
    "class SuggesterTarget(Suggester):\n",
    "    def _build_query(self, text):\n",
    "        return QueryTarget(text=text, tokenizer=self.tokenizer, morpher=self.morpher)\n",
    "    \n",
    "    def _get_matches(self, q, query_type):\n",
    "        if query_type == 'fulltext':\n",
    "            return self.matcher.get_query_matches(q.build_es_query(q.get_fulltext_queries()), n_matches=5)\n",
    "        if query_type == 'phrase':\n",
    "            return self.matcher.get_query_matches(q.build_es_query(q.get_phrase_queries()), n_matches=10)\n",
    "        if query_type == 'single':\n",
    "            single_queries = q.get_single_capital_queries()\n",
    "            return [self.matcher.get_query_matches(q.build_es_query(single_query), n_matches=5)\n",
    "                   for single_query in single_queries]\n",
    "    \n",
    "    def _select_matches(self, q, min_total=5, f=3, p=4, s=1):\n",
    "        return super()._select_matches(q, min_total, f, p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T10:08:40.647880Z",
     "start_time": "2020-01-21T10:08:40.643000Z"
    }
   },
   "outputs": [],
   "source": [
    "mrph = Morpher()\n",
    "mtc = Matcher(es_instance=es)\n",
    "suggester = Suggester(matcher=mtc, tokenizer=tokenizer, morpher=mrph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T12:13:22.087118Z",
     "start_time": "2020-01-28T12:13:15.225350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: В каком австрийском городе расположен Музей кофе?\n",
      "\n",
      "Генуэзская крепость (Феодосия)\n",
      "(Каффа)\n",
      "Link: https://www.wikidata.org/wiki/Q4135566\n",
      "\n",
      "Коба (город)\n",
      "Link: https://www.wikidata.org/wiki/Q1104936\n",
      "\n",
      "Город кошек\n",
      "(Полнометражный документальный фильм о бродячих кошках, населяющих город Стамбул)\n",
      "Link: https://www.wikidata.org/wiki/Q24672271\n",
      "\n",
      "Коро\n",
      "Link: https://www.wikidata.org/wiki/Q1134454\n",
      "\n",
      "Музей мумий\n",
      "Link: https://www.wikidata.org/wiki/Q785223\n",
      "\n",
      "Австрийский музей прикладного искусства\n",
      "(музей в Вене)\n",
      "Link: https://www.wikidata.org/wiki/Q478455\n",
      "\n",
      "Сокол\n",
      "(город в Сокольском районе Вологодской области России)\n",
      "Link: https://www.wikidata.org/wiki/Q196378\n",
      "\n",
      "муза\n",
      "(покровительницы искусств и наук)\n",
      "Link: https://www.wikidata.org/wiki/Q66016\n",
      "\n",
      "{'text': 'В каком австрийском городе расположен Музей кофе?', 'answer': '', 'matches': [{'qid': 'Q4135566', 'label': 'Кафа город', 'score': 13.625122, 'name': 'Генуэзская крепость (Феодосия)', 'description': 'Каффа', 'ruwiki': 'Генуэзская крепость (Феодосия)', 'views': 1610, 'source': 'fulltext'}, {'qid': 'Q1104936', 'label': 'Коба город', 'score': 13.625122, 'name': 'Коба (город)', 'description': None, 'ruwiki': 'Коба (майя)', 'views': 737, 'source': 'fulltext'}, {'qid': 'Q24672271', 'label': 'Город котов', 'score': 13.625122, 'name': 'Город кошек', 'description': 'Полнометражный документальный фильм о бродячих кошках, населяющих город Стамбул', 'ruwiki': 'Город кошек', 'views': 320, 'source': 'fulltext'}, {'qid': 'Q1134454', 'label': 'Коро город', 'score': 13.625122, 'name': 'Коро', 'description': None, 'ruwiki': 'Коро', 'views': 209, 'source': 'fulltext'}, {'qid': 'Q785223', 'label': 'Музей мумий', 'score': 12.290472, 'name': 'Музей мумий', 'description': None, 'ruwiki': 'Музей мумий (Гуанахуато)', 'views': 281, 'source': 'fulltext'}, {'qid': 'Q478455', 'label': 'Австрийский музей прикладного искусства', 'score': 12.148895, 'name': 'Австрийский музей прикладного искусства', 'description': 'музей в Вене', 'ruwiki': 'Музей прикладного искусства (Вена)', 'views': 249, 'source': 'fulltext'}, {'qid': 'Q196378', 'label': 'Со кол город', 'score': 11.375547, 'name': 'Сокол', 'description': 'город в Сокольском районе Вологодской области России', 'ruwiki': 'Сокол (город)', 'views': 1510, 'source': 'fulltext'}, {'qid': 'Q66016', 'label': 'муза', 'score': 9.192063, 'name': 'муза', 'description': 'покровительницы искусств и наук', 'ruwiki': 'Музы', 'views': 11186, 'source': 'single'}]}\n",
      "Make suggestions executed in 6.847 s.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Make suggestions'):\n",
    "    suggestions = suggester.get_suggestions('В каком австрийском городе расположен Музей кофе?')\n",
    "    print(Suggester.pretty_print(suggestions))\n",
    "    print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get entites from questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T10:12:24.617548Z",
     "start_time": "2020-01-21T10:12:24.613147Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "suggestions_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T11:34:24.347763Z",
     "start_time": "2020-01-21T10:23:04.948552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db925ce4c5c420e8ea4799ea2b2952b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delim = '######'\n",
    "dataset_num = '14001_end'\n",
    "with open(f'matching/quiz_dataset_{dataset_num}.txt', 'r') as dataset, \\\n",
    "     open(f'matching/quiz_entities_{dataset_num}.txt', 'a') as pretty:\n",
    "    for i, line in enumerate(tqdm(dataset)):\n",
    "        if i < 3426:\n",
    "            continue\n",
    "        if i % 2 == 0:\n",
    "            question = line.strip('\\n')\n",
    "        if i % 2 == 1:\n",
    "            answer = line.strip('\\n')\n",
    "            print(delim, file=pretty)\n",
    "            print(f'{i // 2 + 1}. ', end='', file=pretty)\n",
    "            suggestions = suggester.get_suggestions(question, answer)\n",
    "            suggestions_data.append(suggestions)\n",
    "            with open(f'matching/quiz_entities_data_{dataset_num}.json', 'w') as results:\n",
    "                json.dump(suggestions_data, results, indent=4, ensure_ascii=False)\n",
    "            print(Suggester.pretty_print(suggestions), file=pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get entites from answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T12:34:57.419415Z",
     "start_time": "2019-10-13T12:34:57.415300Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "suggestions_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:38:43.061540Z",
     "start_time": "2019-10-13T12:35:19.038862Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6018a9b74da5442f8b74eaa2b134d699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delim = '######'\n",
    "with open('matching/quiz_dataset_14001_end.txt', 'r') as dataset, \\\n",
    "     open('matching/quiz_answer_entities_14001_end.txt', 'a') as pretty:\n",
    "    for i, line in enumerate(tqdm(dataset)):\n",
    "        if i % 2 == 0:\n",
    "            question = line.strip('\\n')\n",
    "            continue\n",
    "        answer = line.strip('\\n')\n",
    "        print(delim, file=pretty)\n",
    "        print(f'{i // 2 + 1}.', file=pretty)\n",
    "        print(f'Question: {question}', file=pretty)\n",
    "        suggestions = suggester.get_suggestions(answer)\n",
    "        suggestions['question'] = question\n",
    "        suggestions_data.append(suggestions)\n",
    "        with open('matching/quiz_answer_entities_data_14001_end.json', 'w') as results:\n",
    "            json.dump(suggestions_data, results, indent=4, ensure_ascii=False)\n",
    "        print(Suggester.pretty_print(suggestions), file=pretty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T12:34:30.838344Z",
     "start_time": "2019-10-13T12:34:30.813069Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(suggestions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'В каком году была Хиросима и Нагасаки?',\n",
       " 'matches': [{'qid': 'Q488',\n",
       "   'label': 'атомные бомбардировки Хиросимы и Нагасаки',\n",
       "   'score': 17.550804,\n",
       "   'name': 'атомные бомбардировки Хиросимы и Нагасаки',\n",
       "   'description': 'бомбардировки атомными бомбами японских городов 6 и 9 августа 1945 года',\n",
       "   'ruwiki': 'Атомные бомбардировки Хиросимы и Нагасаки',\n",
       "   'views': 68446,\n",
       "   'source': 'phrase'},\n",
       "  {'qid': 'Q169376',\n",
       "   'label': 'Нагасаки',\n",
       "   'score': 12.959096,\n",
       "   'name': 'Нагасаки',\n",
       "   'description': 'префектура Японии',\n",
       "   'ruwiki': 'Нагасаки (префектура)',\n",
       "   'views': 335,\n",
       "   'source': 'fulltext'},\n",
       "  {'qid': 'Q617375',\n",
       "   'label': 'Хиросима',\n",
       "   'score': 12.252915,\n",
       "   'name': 'Хиросима',\n",
       "   'description': 'префектура Японии',\n",
       "   'ruwiki': 'Хиросима (префектура)',\n",
       "   'views': 371,\n",
       "   'source': 'fulltext'},\n",
       "  {'qid': 'Q11276735',\n",
       "   'label': 'Хиросима',\n",
       "   'score': 12.252915,\n",
       "   'name': 'Хиросима',\n",
       "   'description': None,\n",
       "   'ruwiki': 'Хиросима (фильм, 1953)',\n",
       "   'views': 252,\n",
       "   'source': 'fulltext'},\n",
       "  {'qid': 'Q1141203',\n",
       "   'label': 'Хиросима',\n",
       "   'score': 12.252915,\n",
       "   'name': 'Хиросима',\n",
       "   'description': None,\n",
       "   'ruwiki': 'Хиросима (княжество)',\n",
       "   'views': 89,\n",
       "   'source': 'fulltext'},\n",
       "  {'qid': 'Q1304426',\n",
       "   'label': 'Нагамаки',\n",
       "   'score': 11.107797,\n",
       "   'name': 'Нагамаки',\n",
       "   'description': None,\n",
       "   'ruwiki': 'Нагамаки',\n",
       "   'views': 1304,\n",
       "   'source': 'fulltext'},\n",
       "  {'qid': 'Q34664',\n",
       "   'label': 'Хиросима Хиросима',\n",
       "   'score': 15.816826,\n",
       "   'name': 'Хиросима',\n",
       "   'description': 'город в Японии',\n",
       "   'ruwiki': 'Хиросима',\n",
       "   'views': 14342,\n",
       "   'source': 'single'},\n",
       "  {'qid': 'Q38234',\n",
       "   'label': 'Нагасаки Нагасаки',\n",
       "   'score': 14.573887,\n",
       "   'name': 'Нагасаки',\n",
       "   'description': 'город Японии с расширенным самоуправлением',\n",
       "   'ruwiki': 'Нагасаки',\n",
       "   'views': 7091,\n",
       "   'source': 'single'}]}"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer('Какое прозвище носил король Англии Ричард I?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'какой',\n",
       "    'wt': 0.9940105847,\n",
       "    'gr': 'APRO=(вин,ед,сред|им,ед,сред)'}],\n",
       "  'text': 'Какое'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'прозвище',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(пр,ед|вин,ед|им,ед)'}],\n",
       "  'text': 'прозвище'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'носить',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=прош,ед,изъяв,муж'}],\n",
       "  'text': 'носил'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'король', 'wt': 1, 'gr': 'S,муж,од=им,ед'}],\n",
       "  'text': 'король'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'англия',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,гео,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'Англии'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'ричард',\n",
       "    'wt': 0.9724140581,\n",
       "    'gr': 'S,имя,муж,од=им,ед'}],\n",
       "  'text': 'Ричард'},\n",
       " {'text': ' '},\n",
       " {'analysis': [], 'text': 'I'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrph.analyze(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'token': 'ричард',\n",
       "   'start_offset': 0,\n",
       "   'end_offset': 6,\n",
       "   'type': 'word',\n",
       "   'position': 0},\n",
       "  {'token': 'i',\n",
       "   'start_offset': 7,\n",
       "   'end_offset': 8,\n",
       "   'type': 'word',\n",
       "   'position': 1}]}"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = {\n",
    "    'tokenizer': 'whitespace',\n",
    "    'filter': ['lowercase', 'snow_stem'],\n",
    "#     'text': 'Эскиз декорации III го акт оперы А Спендиарова  Алмаст '\n",
    "    'text': 'Ричард I'\n",
    "}\n",
    "\n",
    "es.indices.analyze(index='label_single', body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'максим',\n",
       "    'wt': 0.8066484349,\n",
       "    'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}],\n",
       "  'text': 'Максима'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'галкин',\n",
       "    'wt': 0.7169838121,\n",
       "    'gr': 'S,фам,муж,од=(вин,ед|род,ед)'}],\n",
       "  'text': 'Галкина'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem.analyze(tokenizer('Кого сыграл Жан Рено в фильме \"Ее звали Никита\"?'))\n",
    "mystem.analyze('Максима Галкина')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_pos_tags = [\n",
    "    'ADVPRO',\n",
    "    'APRO',\n",
    "    'CONJ',\n",
    "    'INTJ',\n",
    "    'PART',\n",
    "    'PR',\n",
    "    'SPRO',\n",
    "    'V',\n",
    "    'ADV'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resp = requests.get('https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&ids=Q3656114|Q17&sitefilter=ruwiki&props=sitelinks')\n",
    "resp = requests.get('https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&ids=Q3656114|Q17&languages=ru&props=labels|descriptions')\n",
    "# resp = requests.get('https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/ru.wikipedia/all-access/all-agents/Обама,_Барак/monthly/2019010100/2019013100')\n",
    "# resp = requests.get('https://ru.wikipedia.org/w/api.php?action=query&format=json&prop=pageviews&pvipdays=20&titles=(2208)_Пушкин')\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': {'Q3656114': {'type': 'item',\n",
       "   'id': 'Q3656114',\n",
       "   'labels': {'ru': {'language': 'ru',\n",
       "     'value': 'История государства Российского'}},\n",
       "   'descriptions': {}},\n",
       "  'Q17': {'type': 'item',\n",
       "   'id': 'Q17',\n",
       "   'labels': {'ru': {'language': 'ru', 'value': 'Япония'}},\n",
       "   'descriptions': {'ru': {'language': 'ru',\n",
       "     'value': 'островное государство в Восточной Азии'}}}},\n",
       " 'success': 1}"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resp.json()['query']['pages'].values()\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 'label_single',\n",
       " 'shard': 0,\n",
       " 'primary': False,\n",
       " 'current_state': 'unassigned',\n",
       " 'unassigned_info': {'reason': 'INDEX_CREATED',\n",
       "  'at': '2019-08-18T22:52:42.694Z',\n",
       "  'last_allocation_status': 'no_attempt'},\n",
       " 'cluster_info': {'nodes': {'T3rpd-0gSEePSbG0hzcyMA': {'node_name': 'Air-Vladislav.Dlink',\n",
       "    'least_available': {'path': '/usr/local/var/lib/elasticsearch/nodes/0',\n",
       "     'total_bytes': 121123069952,\n",
       "     'used_bytes': 114139070464,\n",
       "     'free_bytes': 6983999488,\n",
       "     'free_disk_percent': 5.8,\n",
       "     'used_disk_percent': 94.2},\n",
       "    'most_available': {'path': '/usr/local/var/lib/elasticsearch/nodes/0',\n",
       "     'total_bytes': 121123069952,\n",
       "     'used_bytes': 114139070464,\n",
       "     'free_bytes': 6983999488,\n",
       "     'free_disk_percent': 5.8,\n",
       "     'used_disk_percent': 94.2}}},\n",
       "  'shard_sizes': {'[label_list][0][p]_bytes': 283,\n",
       "   '[label_single][0][p]_bytes': 443925562,\n",
       "   '[labels][0][p]_bytes': 53812},\n",
       "  'shard_paths': {'[labels][0], node[T3rpd-0gSEePSbG0hzcyMA], [P], s[STARTED], a[id=D_zsl-unSMqIhOLH9CXJ9g]': '/usr/local/var/lib/elasticsearch/nodes/0',\n",
       "   '[label_single][0], node[T3rpd-0gSEePSbG0hzcyMA], [P], s[STARTED], a[id=ePKf8_f5QKSs6c26P3uggA]': '/usr/local/var/lib/elasticsearch/nodes/0',\n",
       "   '[label_list][0], node[T3rpd-0gSEePSbG0hzcyMA], [P], s[STARTED], a[id=ugpfPj8NQDiJ_yLS4oG6bQ]': '/usr/local/var/lib/elasticsearch/nodes/0'}},\n",
       " 'can_allocate': 'no',\n",
       " 'allocate_explanation': 'cannot allocate because allocation is not permitted to any of the nodes',\n",
       " 'node_allocation_decisions': [{'node_id': 'T3rpd-0gSEePSbG0hzcyMA',\n",
       "   'node_name': 'Air-Vladislav.Dlink',\n",
       "   'transport_address': '127.0.0.1:9300',\n",
       "   'node_attributes': {'ml.machine_memory': '8589934592',\n",
       "    'xpack.installed': 'true',\n",
       "    'ml.max_open_jobs': '20'},\n",
       "   'node_decision': 'no',\n",
       "   'weight_ranking': 1,\n",
       "   'deciders': [{'decider': 'same_shard',\n",
       "     'decision': 'NO',\n",
       "     'explanation': 'the shard cannot be allocated to the same node on which a copy of the shard already exists [[label_single][0], node[T3rpd-0gSEePSbG0hzcyMA], [P], s[STARTED], a[id=ePKf8_f5QKSs6c26P3uggA]]'}]}]}"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.cluster.allocation_explain(include_disk_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T06:28:31.236189Z",
     "start_time": "2019-09-19T06:28:30.923401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batchcomplete': ''}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiapi_query = f'https://ru.wikipedia.org/w/api.php?action=query&format=json&prop=pageviews&pvipdays=30&titles='\n",
    "resp = requests.get(wikiapi_query).json()\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T23:46:39.974359Z",
     "start_time": "2019-09-29T23:46:39.769130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trtr = json_read('matching/quiz_answer_entities_data_5001_10000.json')\n",
    "len(trtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T14:46:49.745308Z",
     "start_time": "2020-03-04T14:46:43.988422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4114595"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qst = set()\n",
    "with open('labels_token.txt', 'r') as inf:\n",
    "    for line in inf:\n",
    "        qid = line.split(':')[0]\n",
    "        qst.add(qid)\n",
    "len(qst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T14:45:34.991024Z",
     "start_time": "2020-03-04T14:45:32.459510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 5430657,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index='label_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kbqa]",
   "language": "python",
   "name": "conda-env-kbqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
