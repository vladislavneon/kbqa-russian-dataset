{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import re\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(token_pattern=r'\\w+')\n",
    "analyzer = cv.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_q = []\n",
    "full_q_freq = []\n",
    "with open('yaqq_full.tsv', 'r') as inf:\n",
    "    for line in inf:\n",
    "        q = ' '.join(line.strip().split()[:-1])\n",
    "        full_q.append(' '.join(analyzer(q)))\n",
    "        full_q_freq.append(int(line.strip().split()[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all filters\n",
    "\n",
    "def filter_shorter_than_n(q, n=2):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    return len(q.split()) > n\n",
    "\n",
    "def filter_starts_with_how(q):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    words = q.split()\n",
    "    if words[0] != 'как':\n",
    "        return True\n",
    "    whitelist = [\n",
    "        'зовут',\n",
    "        'звали',\n",
    "        'называется',\n",
    "        'называли',\n",
    "        'называют',\n",
    "        'называлось',\n",
    "        'назывались',\n",
    "        'называлась',\n",
    "        'назывался',\n",
    "        'называются'\n",
    "    ]\n",
    "    if words[1] in whitelist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter_starts_with_what(q):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    words = q.split()\n",
    "    if words[0] != 'что':\n",
    "        return True\n",
    "    blacklist = [\n",
    "        'будет',\n",
    "        'нужно',\n",
    "        'делать',\n",
    "        'можно',\n",
    "        'лучше'\n",
    "    ]\n",
    "    if words[1] in blacklist:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def filter_stop_words(q):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    stop_words = set([\n",
    "        'купить',\n",
    "        'почему',\n",
    "        'онлайн',\n",
    "        'сегодня',\n",
    "        'лучше',\n",
    "        'зачем',\n",
    "        'снится',\n",
    "        'приготовить',\n",
    "        'беременности',\n",
    "        'видео',\n",
    "        'документы',\n",
    "        'тест', \n",
    "        'подарить', \n",
    "        'снятся', \n",
    "        'калорий',\n",
    "        'беременным', \n",
    "        'бесплатно', \n",
    "        'нужен',\n",
    "        'нужна',\n",
    "        'нужно',\n",
    "        'нужны',\n",
    "        'отдохнуть', \n",
    "        'сниться', \n",
    "        'нельзя', \n",
    "        'заниматься', \n",
    "        'беременность', \n",
    "        'отдыхать', \n",
    "        'выбрать',\n",
    "        'забеременеть', \n",
    "        'месячных', \n",
    "        'сексом', \n",
    "        'похудеть', \n",
    "        'контакте', \n",
    "        'загранпаспорт',\n",
    "        'сайт',\n",
    "        'может',\n",
    "        'фото'\n",
    "    ])\n",
    "    words = q.split()\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_stop_substr(q):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    stop_substr = [\n",
    "        '100 к 1',\n",
    "        'сто к одному',\n",
    "        'можно ли',\n",
    "        'где можно'\n",
    "    ]\n",
    "    for sb in stop_substr:\n",
    "        if sb in q:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_starts_with_stop_words(q):\n",
    "    q = ' '.join(analyzer(q))\n",
    "    stop_words = [\n",
    "        'игра',\n",
    "        'игры',\n",
    "        'с чем',\n",
    "        'чем ',\n",
    "        'сколько стоит',\n",
    "        'где отметить',\n",
    "        'где отпраздновать',\n",
    "        'что подарить'\n",
    "    ]\n",
    "    for sw in stop_words:\n",
    "        if q.startswith(sw):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_must_start_with_question_word(q):\n",
    "    ws = ' '.join(analyzer(q))\n",
    "    q_words = [\n",
    "        'кто ',\n",
    "        'где ',\n",
    "        'когда ',\n",
    "        'какой ',\n",
    "        'каком '\n",
    "    ]\n",
    "    for qw in q_words:\n",
    "        if qw in ws:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def filter_unknown_words(q):\n",
    "    ws = analyzer(q)\n",
    "    for w in ws:\n",
    "        if w not in russ_vocab:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(q, filters):\n",
    "    new_q = q\n",
    "    for f in filters:\n",
    "        new_q = list(filter(f, new_q))\n",
    "    return new_q\n",
    "\n",
    "def print_q(qs):\n",
    "    for q in qs:\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filters = [\n",
    "    filter_shorter_than_n,\n",
    "    filter_starts_with_how,\n",
    "    filter_starts_with_what,\n",
    "    filter_stop_words,\n",
    "    filter_stop_substr,\n",
    "    filter_starts_with_stop_words\n",
    "]\n",
    "\n",
    "filtered_q = apply_filters(\n",
    "    q=full_q,\n",
    "    filters=all_filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353592\n",
      "сколько нежных слов я не сказал сколько их ненужных обронил\n",
      "сколько серий в сериале остров ненужных людей\n",
      "куда отдать ненужные вещи\n",
      "куда отдать ненужную одежду\n",
      "где продать ненужные вещи\n",
      "где снимался фильм остров ненужных людей\n",
      "где снимали остров ненужных людей\n",
      "сколько серий остров ненужных людей\n",
      "где снимали фильм остров ненужных людей\n",
      "сколько серий в фильме остров ненужных людей\n",
      "что полезного и нужного вы могли бы предложить компании\n",
      "будет ли продолжение сериала остров ненужных людей\n",
      "сколько серий в острове ненужных людей\n",
      "потому что потому что всех нужнее и дороже\n",
      "куда сдать ненужную одежду\n",
      "куда можно отдать ненужную одежду\n",
      "программа которая удаляет ненужные файлы\n",
      "куда деть ненужную одежду\n",
      "куда сдать ненужные вещи\n",
      "где снимался остров ненужных людей\n",
      "куда деть ненужные книги\n",
      "сколько серий в остров ненужных людей\n",
      "где снимался сериал остров ненужных людей\n",
      "на каком острове снимался фильм остров ненужных людей\n",
      "где снимали сериал остров ненужных людей\n",
      "куда деть ненужные вещи\n",
      "куда можно отдать ненужные вещи\n",
      "что полезного и нужного вы могли бы предложить компании\n",
      "куда отнести ненужные вещи\n",
      "куда сдать ненужные книги\n",
      "кому отдать ненужные вещи\n",
      "будет ли 2 сезон остров ненужных людей\n",
      "на каком острове снимали фильм остров ненужных людей\n",
      "как называется условие требующее распространения ресурсов между фирмами так чтобы получить нужный обществу ассортимент продукции\n",
      "что полезного и нужного вы могли бы предложить компании\n",
      "куда отдать ненужные книги\n",
      "сколько всего серий в сериале остров ненужных людей\n",
      "что полезного и нужного вы могли бы предложить банку\n",
      "когда ненужно лишних слов\n",
      "куда можно сдать ненужные вещи\n",
      "будет ли продолжение остров ненужных людей\n",
      "куда девать ненужные вещи\n",
      "bat как сделать чтобы письмо приходило в нужную папку\n",
      "что сделать из ненужных вещей\n",
      "не кому не нужная\n",
      "сколько серий фильма остров ненужных людей\n",
      "куда можно сдать ненужную одежду\n",
      "сколько побед осталось до нужного процента побед\n",
      "где посмотреть остров ненужных людей\n",
      "кто исполняет песню в сериале остров ненужных людей\n",
      "когда закончится сериал остров ненужных людей\n",
      "где проходили съемки фильма остров ненужных людей\n",
      "кто снимался в фильме остров ненужных людей\n",
      "когда выйдет 2 сезон остров ненужных людей\n",
      "что нужнее истина или сострадание\n",
      "будет ли продолжение фильма остров ненужных людей\n",
      "сколько всего серий остров ненужных людей\n",
      "кто исполняет песню в фильме остров ненужных людей\n",
      "о чем фильм остров ненужных людей\n",
      "куда можно отнести ненужные вещи\n",
      "куда девать ненужные книги\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_q))\n",
    "cnt = 0\n",
    "for q in filtered_q:\n",
    "    if 'нужн' in q:\n",
    "        cnt += 1\n",
    "        print(q)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finder_substr(q, prop):\n",
    "    if re.search(prop, q) is not None:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_properties_finder(q, finder, prop):\n",
    "    f = partial(finder, prop=prop)\n",
    "    return list(filter(f, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_property(aliases):\n",
    "    qs = []\n",
    "    for alias in aliases:\n",
    "        cur_qs = apply_properties_finder(filtered_q, finder_substr, alias)\n",
    "        qs.extend(cur_qs)\n",
    "    return qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('properties_aliases.json', 'r') as inf:\n",
    "    prop_aliases = json.load(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'P143'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-d3b8303be761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P143'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'P143'"
     ]
    }
   ],
   "source": [
    "find_property(prop_aliases['P143'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['имя при рождении', 'на родном языке', 'оригинал имени', 'оригинальное имя']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_aliases['P1559']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\\n"
     ]
    }
   ],
   "source": [
    "print('\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kbqa]",
   "language": "python",
   "name": "conda-env-kbqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
